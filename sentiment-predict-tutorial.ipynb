{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8faa0994-9760-4a48-b71b-9f218b963cea",
   "metadata": {},
   "source": [
    "# Review Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98bf12a8-9c72-4a34-9996-984d99bd89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score of 4 or 5\n",
    "            return Sentiment.POSITIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3814c-2749-42f1-adf9-f5cf624db8e5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f63cf3fd-8d16-4088-82fa-0593ae65cc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = './books_small.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "\n",
    "reviews[5].text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484c473-546a-4fdd-9706-b331f50b9782",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b17ec5d-c160-4ff2-9ed4-3ef0fc6f5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15651e60-4dc7-4713-a099-f034df04ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [x.text for x in training]\n",
    "y_train = [x.sentiment for x in training]\n",
    "\n",
    "X_test = [x.text for x in test]\n",
    "y_test = [x.sentiment for x in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f27231-4217-429a-a404-f427b7523884",
   "metadata": {},
   "source": [
    "# Bags of Words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7c9f176-9aeb-402f-9cad-4500923e87a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# fit and transform training data\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# transform test data\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18af34b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e3bad03",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ed78c",
   "metadata": {},
   "source": [
    "### Linear SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff086bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every new Myke Cole book is better than the last, and this is no exception. If you haven't read the Shadow Ops series before start with Control Point, but go ahead and order Fortress Frontier and Breach Zone as well - you're going to want them.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(X_train_vectors, y_train)\n",
    "\n",
    "print(X_test[0])\n",
    "clf_svm.predict(X_test_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bea78e",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba451dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "\n",
    "clf_dec.fit(X_train_vectors, y_train)\n",
    "\n",
    "clf_dec.predict(X_test_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ddea0",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f1e1fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "clf_gnb.fit(X_train_vectors.toarray(), y_train)\n",
    "\n",
    "clf_gnb.predict(X_test_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd72a3",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0fe312e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "\n",
    "clf_log.fit(X_train_vectors, y_train)\n",
    "\n",
    "clf_log.predict(X_test_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376cdc5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2163669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8242424242424242\n",
      "0.7818181818181819\n",
      "0.8121212121212121\n",
      "0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "# MEAN ACCURACY\n",
    "# Comparison of test vectors and test data\n",
    "# .score() method returns the mean accuracy on the given test data and labels.\n",
    "print(clf_svm.score(X_test_vectors, y_test))\n",
    "print(clf_dec.score(X_test_vectors, y_test))\n",
    "print(clf_gnb.score(X_test_vectors.toarray(), y_test))\n",
    "print(clf_log.score(X_test_vectors, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c106845a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91319444, 0.21052632, 0.22222222])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 SCORE\n",
    "# The F1 score can be interpreted as a weighted average of the precision and recall,\n",
    "# where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, clf_svm.predict(X_test_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE])\n",
    "# output: array([0.91319444, 0.21052632, 0.22222222])\n",
    "# this result shows that the model is good at predicting positive reviews, but not good at predicting neutral and negative reviews\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
